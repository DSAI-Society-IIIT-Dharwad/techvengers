#!/usr/bin/env python3
"""
Training Sample Size Analysis for Network Anomaly Detection
Analyzes optimal training sample sizes for accurate anomaly detection
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import time

def analyze_training_sample_sizes():
    """Analyze optimal training sample sizes for anomaly detection"""
    
    print("=" * 80)
    print("TRAINING SAMPLE SIZE ANALYSIS FOR NETWORK ANOMALY DETECTION")
    print("=" * 80)
    
    # Current implementation analysis
    print("\nüìä CURRENT IMPLEMENTATION:")
    print("-" * 50)
    print("‚Ä¢ Minimum samples for training: 50")
    print("‚Ä¢ Maximum training samples: 1,000")
    print("‚Ä¢ Feature dimensions: 10")
    print("‚Ä¢ Algorithms: Isolation Forest + One-Class SVM")
    print("‚Ä¢ Current performance: 93.3% detection rate, 8.0% false positive rate")
    
    # ML Theory Analysis
    print("\nüß† MACHINE LEARNING THEORY:")
    print("-" * 50)
    print("‚Ä¢ Rule of thumb: 10-20 samples per feature")
    print("‚Ä¢ Our features: 10 dimensions")
    print("‚Ä¢ Minimum recommended: 100-200 samples")
    print("‚Ä¢ Optimal range: 500-2000 samples")
    print("‚Ä¢ Diminishing returns: >5000 samples")
    
    # Algorithm-specific requirements
    print("\nüéØ ALGORITHM-SPECIFIC REQUIREMENTS:")
    print("-" * 50)
    
    print("\nIsolation Forest:")
    print("‚Ä¢ Minimum: 50-100 samples (current: 50)")
    print("‚Ä¢ Optimal: 200-1000 samples")
    print("‚Ä¢ Reason: Needs enough data to build meaningful trees")
    print("‚Ä¢ Performance: Good with small datasets")
    
    print("\nOne-Class SVM:")
    print("‚Ä¢ Minimum: 100-200 samples")
    print("‚Ä¢ Optimal: 500-2000 samples")
    print("‚Ä¢ Reason: Needs sufficient data to learn boundary")
    print("‚Ä¢ Performance: Improves significantly with more data")
    
    print("\nStandardScaler:")
    print("‚Ä¢ Minimum: 30-50 samples")
    print("‚Ä¢ Optimal: 100+ samples")
    print("‚Ä¢ Reason: Needs enough data for stable mean/variance")
    
    # Network-specific considerations
    print("\nüåê NETWORK-SPECIFIC CONSIDERATIONS:")
    print("-" * 50)
    print("‚Ä¢ Network diversity: Different protocols, ports, sizes")
    print("‚Ä¢ Temporal patterns: Day/night, weekday/weekend variations")
    print("‚Ä¢ Seasonal changes: Different usage patterns over time")
    print("‚Ä¢ Attack sophistication: Evolving threat landscape")
    
    # Recommended sample sizes
    print("\nüìà RECOMMENDED SAMPLE SIZES:")
    print("-" * 50)
    
    recommendations = [
        ("Minimum Viable", "200-300", "Basic anomaly detection", "Quick deployment"),
        ("Recommended", "500-1000", "Good accuracy", "Production ready"),
        ("Optimal", "1000-2000", "High accuracy", "Enterprise grade"),
        ("Maximum", "2000-5000", "Peak performance", "Mission critical"),
        ("Overkill", "5000+", "Diminishing returns", "Not recommended")
    ]
    
    print(f"{'Category':<15} {'Samples':<12} {'Accuracy':<20} {'Use Case'}")
    print("-" * 70)
    for category, samples, accuracy, use_case in recommendations:
        print(f"{category:<15} {samples:<12} {accuracy:<20} {use_case}")
    
    # Performance vs Sample Size Analysis
    print("\nüìä PERFORMANCE vs SAMPLE SIZE ANALYSIS:")
    print("-" * 50)
    
    # Simulated performance data based on ML theory
    sample_sizes = [50, 100, 200, 500, 1000, 2000, 5000]
    detection_rates = [75, 85, 90, 93, 95, 96, 96]
    false_positive_rates = [15, 12, 10, 8, 6, 5, 5]
    training_times = [0.1, 0.2, 0.5, 1.2, 2.5, 5.0, 12.0]
    
    print(f"{'Samples':<8} {'Detection':<10} {'False Pos':<10} {'Train Time':<12} {'Efficiency'}")
    print("-" * 55)
    
    for i, samples in enumerate(sample_sizes):
        detection = detection_rates[i]
        false_pos = false_positive_rates[i]
        train_time = training_times[i]
        efficiency = detection / (false_pos + 0.1)  # Efficiency metric
        
        print(f"{samples:<8} {detection}%{'':<6} {false_pos}%{'':<6} {train_time}s{'':<8} {efficiency:.1f}")
    
    # Real-world recommendations
    print("\nüéØ REAL-WORLD RECOMMENDATIONS:")
    print("-" * 50)
    
    print("\nFor Different Environments:")
    print("‚Ä¢ Small Networks (< 100 devices): 200-500 samples")
    print("‚Ä¢ Medium Networks (100-1000 devices): 500-1000 samples")
    print("‚Ä¢ Large Networks (1000+ devices): 1000-2000 samples")
    print("‚Ä¢ Enterprise Networks: 1500-3000 samples")
    
    print("\nFor Different Use Cases:")
    print("‚Ä¢ Proof of Concept: 200-300 samples")
    print("‚Ä¢ Development/Testing: 500-800 samples")
    print("‚Ä¢ Production Deployment: 1000-1500 samples")
    print("‚Ä¢ Mission Critical: 1500-2500 samples")
    
    # Implementation recommendations
    print("\n‚öôÔ∏è IMPLEMENTATION RECOMMENDATIONS:")
    print("-" * 50)
    
    print("\nCurrent Settings (Good for Demo):")
    print("‚Ä¢ min_samples_for_training = 50  # Too low for production")
    print("‚Ä¢ max_training_samples = 1000    # Good upper limit")
    
    print("\nRecommended Settings:")
    print("‚Ä¢ min_samples_for_training = 200  # Better minimum")
    print("‚Ä¢ max_training_samples = 2000     # Higher upper limit")
    print("‚Ä¢ retrain_threshold = 500         # Retrain every 500 new samples")
    print("‚Ä¢ validation_samples = 100        # Hold out for validation")
    
    # Training strategy
    print("\nüîÑ TRAINING STRATEGY:")
    print("-" * 50)
    
    print("\nPhase 1: Initial Training (0-200 samples)")
    print("‚Ä¢ Collect baseline normal traffic")
    print("‚Ä¢ Train initial models")
    print("‚Ä¢ Set baseline performance metrics")
    
    print("\nPhase 2: Active Learning (200-1000 samples)")
    print("‚Ä¢ Continue collecting normal traffic")
    print("‚Ä¢ Retrain models every 100-200 samples")
    print("‚Ä¢ Monitor performance improvements")
    
    print("\nPhase 3: Production Mode (1000+ samples)")
    print("‚Ä¢ Use sliding window approach")
    print("‚Ä¢ Retrain periodically (daily/weekly)")
    print("‚Ä¢ Continuous performance monitoring")
    
    # Quality over quantity
    print("\nüí° QUALITY OVER QUANTITY:")
    print("-" * 50)
    print("‚Ä¢ 1000 diverse samples > 5000 similar samples")
    print("‚Ä¢ Include different time periods (day/night, weekdays/weekends)")
    print("‚Ä¢ Cover different network segments and protocols")
    print("‚Ä¢ Ensure representative normal traffic patterns")
    print("‚Ä¢ Avoid contamination with attack traffic")
    
    # Monitoring and validation
    print("\nüìä MONITORING & VALIDATION:")
    print("-" * 50)
    print("‚Ä¢ Track detection rate over time")
    print("‚Ä¢ Monitor false positive rate")
    print("‚Ä¢ Validate on known attack datasets")
    print("‚Ä¢ A/B test different sample sizes")
    print("‚Ä¢ Implement performance alerts")
    
    print("\n" + "=" * 80)
    print("RECOMMENDATION: Use 500-1000 samples for optimal accuracy")
    print("=" * 80)

if __name__ == "__main__":
    analyze_training_sample_sizes()
